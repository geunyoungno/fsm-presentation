# LLM ì±—ë´‡ ì›Œí¬í”Œë¡œìš° ë¹„êµ

> **í•µì‹¬ ì§ˆë¬¸:** LLM ì±—ë´‡ì„ ë§Œë“¤ ë•Œ ì–´ë–¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„ íƒí•´ì•¼ í• ê¹Œ?

ë™ì¼í•œ LLM ì±—ë´‡ ì›Œí¬í”Œë¡œìš°ë¥¼ ì„¸ ê°€ì§€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ êµ¬í˜„í•˜ì—¬ ë¹„êµí•©ë‹ˆë‹¤.

## ì™œ LLMì— FSM/ì›Œí¬í”Œë¡œìš°ê°€ í•„ìš”í•œê°€?

LLMì€ ë¹„ê²°ì •ì ì´ì§€ë§Œ, **ì›Œí¬í”Œë¡œìš°ëŠ” ê²°ì •ì **ì´ì–´ì•¼ í•©ë‹ˆë‹¤. FSM/ì›Œí¬í”Œë¡œìš°ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì´ì ì„ ì œê³µí•©ë‹ˆë‹¤:

### í•µì‹¬ ì´ì 

1. **ğŸ¯ ë¹„ê²°ì •ì  ì¶œë ¥ ì œì–´**
   - LLM ì¶œë ¥ì€ ë§¤ë²ˆ ë‹¤ë¥¼ ìˆ˜ ìˆì§€ë§Œ, FSMì€ **íë¦„ì„ ê²°ì •ì **ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤
   - ì˜ˆ: "ì‚¬ìš©ì ì…ë ¥ â†’ ê²€ì¦ â†’ LLM í˜¸ì¶œ â†’ ì‘ë‹µ" ìˆœì„œëŠ” í•­ìƒ ë™ì¼

2. **ğŸ’° ë¹„ìš© ì ˆê° (4-6ë°°)**
   - StateFlow ì—°êµ¬: ê° ìƒíƒœì— ë§ëŠ” **ì§§ì€ í”„ë¡¬í”„íŠ¸**ë§Œ ì „ì†¡í•˜ì—¬ ë¹„ìš© ì ˆê°
   - ì¶œì²˜: [StateFlow: Enhancing LLM Task-Solving (arXiv)](https://arxiv.org/abs/2403.11322)

3. **ğŸ”’ ë³´ì•ˆ ê°•í™”**
   - ëª…ì‹œì  ìƒíƒœ ì „ì´ë¡œ **í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜ ë°©ì–´**
   - ê° ìƒíƒœì—ì„œ í•„ìš”í•œ ë„êµ¬ë§Œ ì ‘ê·¼ ê°€ëŠ¥ (ìµœì†Œ ê¶Œí•œ ì›ì¹™)

4. **ğŸ”„ ì¬ì‹œë„ ë° ë³µêµ¬**
   - LLM API ì‹¤íŒ¨ ì‹œ **ëª…í™•í•œ ì¬ì‹œë„ ë¡œì§**
   - ì‹¤íŒ¨ íšŸìˆ˜, ëŒ€ê¸° ì‹œê°„ ë“±ì„ ìƒíƒœ ë¨¸ì‹ ì— ëª…ì‹œ

5. **ğŸ§  ì‘ì—… ë¶„í•´ ë° ê²€ì¦**
   - ë³µì¡í•œ ëŒ€í™”ë¥¼ **ë‹¨ê³„ë³„ë¡œ ë¶„í•´**í•˜ì—¬ ê° ë‹¨ê³„ ê²€ì¦ ê°€ëŠ¥
   - ì˜¤ë¥˜ ì „íŒŒ ë°©ì§€ ë° ë””ë²„ê¹… ìš©ì´

> **ê²°ë¡ :** FSM/ì›Œí¬í”Œë¡œìš°ëŠ” LLMì˜ ì°½ì˜ì„±ì€ ìœ ì§€í•˜ë©´ì„œ, ì œì–´ ê°€ëŠ¥ì„±, ë¹„ìš© íš¨ìœ¨ì„±, ì•ˆì •ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.

---

## ì±—ë´‡ ì›Œí¬í”Œë¡œìš° íë¦„

```mermaid
stateDiagram-v2
    [*] --> ì‚¬ìš©ìì…ë ¥
    ì‚¬ìš©ìì…ë ¥ --> ì…ë ¥ê²€ì¦
    ì…ë ¥ê²€ì¦ --> LLMí˜¸ì¶œ: ìœ íš¨
    ì…ë ¥ê²€ì¦ --> ì‹¤íŒ¨: ë¹ˆ ë©”ì‹œì§€
    LLMí˜¸ì¶œ --> ì‘ë‹µì¶œë ¥: ì„±ê³µ
    LLMí˜¸ì¶œ --> ì¬ì‹œë„: ì‹¤íŒ¨ (< 3íšŒ)
    ì¬ì‹œë„ --> LLMí˜¸ì¶œ
    ì¬ì‹œë„ --> ì‹¤íŒ¨: ìµœëŒ€ ì´ˆê³¼
    ì‘ë‹µì¶œë ¥ --> [*]
    ì‹¤íŒ¨ --> [*]
```

## ë¼ì´ë¸ŒëŸ¬ë¦¬ë³„ LLM ì¬ì‹œë„ ì „ëµ ë¹„êµ

ê° ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ LLM í˜¸ì¶œ ì‹¤íŒ¨ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ì‹ì´ ë‹¤ë¦…ë‹ˆë‹¤:

### XState: ìƒíƒœ + after + guard

```typescript
states: {
  calling_llm: {
    invoke: {
      src: fromPromise(async () => await callLLM()),
      onDone: { target: 'response_ready' },
      onError: { target: 'error' }
    }
  },
  error: {
    after: {
      1500: [
        {
          guard: ({ context }) => context.retryCount < 3,
          target: 'calling_llm',  // ì¬ì‹œë„
          actions: assign({ retryCount: (ctx) => ctx.retryCount + 1 })
        },
        { target: 'failed' }  // ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼
      ]
    }
  }
}
```

**íŠ¹ì§•:**
- âœ… ì¬ì‹œë„ ë¡œì§ì´ ìƒíƒœ ë¨¸ì‹ ì— ëª…ì‹œì ìœ¼ë¡œ í‘œí˜„ë¨
- âœ… ì‹œê°í™” ë„êµ¬ì—ì„œ ì¬ì‹œë„ ê²½ë¡œë¥¼ ë³¼ ìˆ˜ ìˆìŒ
- âœ… ê° ê²½ë¡œë¥¼ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
- âš ï¸ ì¬ì‹œë„ ë¡œì§ì´ ìƒíƒœ ì •ì˜ì™€ ë¶„ë¦¬ë¨ (after, guard ì¡°í•© í•„ìš”)

### Mastra: Step ë‚´ë¶€ while ë£¨í”„

```typescript
const callLLM = createStep({
  id: 'call-llm',
  execute: async ({ inputData }) => {
    let state = { ...inputData };
    let success = false;

    while (!success && state.retryCount < MAX_RETRIES) {
      try {
        const response = await callLLM(state.conversationHistory);
        state = { ...state, currentResponse: response, status: 'success' };
        success = true;
      } catch (error) {
        state.retryCount++;
        await delay(1500);
      }
    }

    if (!success) {
      state.status = 'failed';
    }
    return state;
  }
});
```

**íŠ¹ì§•:**
- âœ… Stepì´ ë…ë¦½ì ìœ¼ë¡œ ì¬ì‹œë„ ë¡œì§ì„ ì™„ì „íˆ ì œì–´
- âœ… AI ì‘ì—…(LLM í˜¸ì¶œ)ì˜ ì¬ì‹œë„ì— íŠ¹íˆ ì í•©
- âœ… ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ëŠ” ë‹¨ìˆœí•˜ê²Œ ìœ ì§€
- âœ… [Workflow state](https://mastra.ai/docs/workflows/workflow-state)ë¡œ ìƒíƒœ ì˜ì†í™” ë° suspend/resume ì§€ì›
- âš ï¸ Step ë‚´ë¶€ ë¡œì§ì´ ë³µì¡í•´ì§ˆ ìˆ˜ ìˆìŒ

### LangGraph: ì¡°ê±´ë¶€ ì—£ì§€ (Conditional Edges)

```typescript
// ë…¸ë“œëŠ” ë‹¨ì¼ ì‘ì—…ë§Œ ìˆ˜í–‰ (LLM í˜¸ì¶œ 1íšŒ)
async function callLLMNode(state) {
  try {
    const response = await callLLM(state.conversationHistory);
    return { currentResponse: response, status: 'success' };
  } catch (error) {
    return { retryCount: state.retryCount + 1, status: 'processing' };
  }
}

// ì¡°ê±´ë¶€ ì—£ì§€ê°€ ì¬ì‹œë„ ì—¬ë¶€ ê²°ì •
function routeAfterLLMCall(state) {
  if (state.status === 'success') {
    return 'display_response';
  }
  if (state.retryCount < MAX_RETRIES) {
    return 'call_llm';  // ê°™ì€ ë…¸ë“œë¡œ ë‹¤ì‹œ ë¼ìš°íŒ… (ë£¨í”„)
  }
  return 'handle_failure';
}

workflow.addConditionalEdges('call_llm', routeAfterLLMCall);
```

**íŠ¹ì§•:**
- âœ… ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìì²´ê°€ ì¬ì‹œë„ ê²½ë¡œë¥¼ ëª…ì‹œì ìœ¼ë¡œ í‘œí˜„
- âœ… ë…¸ë“œëŠ” ìˆœìˆ˜í•˜ê³  í…ŒìŠ¤íŠ¸í•˜ê¸° ì‰¬ì›€ (ê´€ì‹¬ì‚¬ì˜ ë¶„ë¦¬)
- âœ… ë³µì¡í•œ ë¶„ê¸° ì²˜ë¦¬ì— ê°•ë ¥
- âš ï¸ ê·¸ë˜í”„ êµ¬ì¡° ì´í•´ í•„ìš”

## ì¬ì‹œë„ ì „ëµ ë¹„êµí‘œ

| ì¸¡ë©´ | XState | Mastra | LangGraph |
|------|--------|--------|-----------|
| **ì¬ì‹œë„ ìœ„ì¹˜** | ìƒíƒœ ë¨¸ì‹  (`after` + `guard`) | Step ë‚´ë¶€ (`while` ë£¨í”„) | ì¡°ê±´ë¶€ ì—£ì§€ (ê·¸ë˜í”„ ë¼ìš°íŒ…) |
| **ì½”ë“œ ì‘ì§‘ë„** | ë¶„ì‚° (ìƒíƒœ ì •ì˜ + after + guard) | ë†’ìŒ (Step ë‚´ë¶€ì— ëª¨ë‘ í¬í•¨) | ì¤‘ê°„ (ë…¸ë“œ + ë¼ìš°í„° í•¨ìˆ˜) |
| **Durable Execution** | âŒ (ë©”ëª¨ë¦¬ ê¸°ë°˜) | â­â­â­ (ìƒíƒœ ì˜ì†í™”, suspend/resume) | â­ (ì œí•œì  ì§€ì›) |
| **ì‹œê°í™”** | â­â­â­ (ìƒíƒœ ë‹¤ì´ì–´ê·¸ë¨) | â­ (ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„) | â­â­ (ë…¸ë“œ + ì—£ì§€ ê·¸ë˜í”„) |
| **í…ŒìŠ¤íŠ¸ ìš©ì´ì„±** | â­â­â­ (ê° ìƒíƒœ ë…ë¦½ í…ŒìŠ¤íŠ¸) | â­â­ (Step ë‹¨ìœ„ í…ŒìŠ¤íŠ¸) | â­â­â­ (ë…¸ë“œ + ë¼ìš°í„° ë¶„ë¦¬) |
| **LLM í†µí•©** | â­ (ìˆ˜ë™) | â­â­â­ (ë„¤ì´í‹°ë¸Œ) | â­â­â­ (LLM íŠ¹í™”) |
| **ì í•©í•œ ê²½ìš°** | UI ì±—ë´‡, ëª…í™•í•œ ìƒíƒœ ì „ì´ | ì¥ê¸° ì‹¤í–‰ AI íŒŒì´í”„ë¼ì¸ | LLM ì—ì´ì „íŠ¸, ë³µì¡í•œ ëŒ€í™” |

## LLM ì›Œí¬í”Œë¡œìš° ì„ íƒ ê°€ì´ë“œ

### XState Chatbotì„ ì„ íƒí•˜ì„¸ìš”:
- âœ“ í”„ë¡ íŠ¸ì—”ë“œ UIì™€ í†µí•©ë˜ëŠ” ì±—ë´‡
- âœ“ ìƒíƒœ ì „ì´ë¥¼ ëª…í™•íˆ ì‹œê°í™”í•˜ê³  ì‹¶ì„ ë•Œ
- âœ“ íƒ€ì… ì•ˆì „ì„±ê³¼ ë””ë²„ê¹…ì´ ì¤‘ìš”
- âœ“ React/Vueì™€ í•¨ê»˜ ì‚¬ìš©

### Mastra Chatbotì„ ì„ íƒí•˜ì„¸ìš”:
- âœ“ ì¥ê¸° ì‹¤í–‰ ë°±ì—”ë“œ AI ì›Œí¬í”Œë¡œìš° (ì„œë²„ë¦¬ìŠ¤ í•¨ìˆ˜, API)
- âœ“ ìƒíƒœ ì˜ì†í™”ì™€ suspend/resumeì´ í•„ìš”í•œ ê²½ìš°
- âœ“ ë‹¤ì–‘í•œ LLM ì œê³µì í†µí•© (OpenAI, Anthropic, Google ë“± 40+ ì§€ì›)
- âœ“ ë³µì¡í•œ ì¬ì‹œë„ ë¡œì§ì´ í•„ìš”í•œ ê²½ìš°
- âœ“ Inngestì™€ ê°™ì€ durable execution ëŸ°íƒ€ì„ í™œìš©

### LangGraph Chatbotì„ ì„ íƒí•˜ì„¸ìš”:
- âœ“ LLM ì—ì´ì „íŠ¸ ê¸°ë°˜ ì‹œìŠ¤í…œ (ReAct, Reflection)
- âœ“ ë„êµ¬ í˜¸ì¶œ(Tool Calling)ì´ í•„ìš”í•œ ê²½ìš°
- âœ“ ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—…
- âœ“ LangChain ìƒíƒœê³„ ì‚¬ìš© ì¤‘

## í•µì‹¬ í†µì°°

### 1. íŒ¨í„´ì˜ ìœ ì‚¬ì„±

ì„¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª¨ë‘ ë™ì¼í•œ ë¬¸ì œ(LLM ì¬ì‹œë„)ë¥¼ í•´ê²°í•˜ì§€ë§Œ, ì ‘ê·¼ ë°©ì‹ì´ ë‹¤ë¦…ë‹ˆë‹¤:

- **XState**: ìƒíƒœ ì¤‘ì‹¬ (State-First)
  - ìƒíƒœ ë¨¸ì‹ ìœ¼ë¡œ ëª¨ë“  ì „ì´ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ëª¨ë¸ë§

- **Mastra**: Step/Workflow ì¤‘ì‹¬ + Stateful Durable Execution
  - Step ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° êµ¬ì„± + ìƒíƒœ ì˜ì†í™” ë° suspend/resume ì§€ì›
  - [Inngest í†µí•©](https://mastra.ai/docs/workflows/inngest-workflow)ìœ¼ë¡œ step memoizationê³¼ ìë™ ì¬ì‹œë„

- **LangGraph**: ê·¸ë˜í”„ ì¤‘ì‹¬ (Graph-First)
  - ë…¸ë“œì™€ ì¡°ê±´ë¶€ ì—£ì§€ë¡œ ë™ì  ë¼ìš°íŒ… êµ¬í˜„

### 2. LLM í†µí•©ì€ ì¼ë°˜ ë¹„ë™ê¸° ì‘ì—…ì˜ ì—°ì¥ì„ 

- `02-xstate-examples`ì˜ `fetch-example.ts`ì™€ `llm-chat.ts`ëŠ” ë™ì¼í•œ íŒ¨í„´
- `invoke` + `fromPromise`ëŠ” REST APIë“  LLM APIë“  ìƒê´€ì—†ì´ ë™ì‘
- ì¬ì‹œë„ ë¡œì§ë„ ë™ì¼ (guard ê¸°ë°˜ ì¡°ê±´ë¶€ ì „ì´)

### 3. ë³µì¡ë„ì™€ ìœ ì—°ì„±ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„

- **XState**: ëª…í™•í•˜ì§€ë§Œ ì´ˆê¸° ì„¤ì •ì´ ë³µì¡
  - ì¥ì : ëª…ì‹œì  ìƒíƒœ ì „ì´, ìš°ìˆ˜í•œ ì‹œê°í™”, UI í†µí•©
  - ë‹¨ì : í•™ìŠµ ê³¡ì„ , durable execution ë¯¸ì§€ì›

- **Mastra**: Step ë‹¨ìˆœì„± + Durable Execution
  - ì¥ì : ìƒíƒœ ì˜ì†í™”, ì¥ê¸° ì‹¤í–‰ ì›Œí¬í”Œë¡œìš°, ë‹¤ì–‘í•œ LLM í†µí•©
  - ë‹¨ì : ë³µì¡í•œ ë¶„ê¸° ì²˜ë¦¬ ì–´ë ¤ì›€, ê·¸ë˜í”„ ì‹œê°í™” ì œí•œì 

- **LangGraph**: ê°•ë ¥í•œ ì—ì´ì „íŠ¸ ì¤‘ì‹¬ ì„¤ê³„
  - ì¥ì : ë™ì  ë¼ìš°íŒ…, LLM ì—ì´ì „íŠ¸ íŠ¹í™”, ë„êµ¬ í˜¸ì¶œ
  - ë‹¨ì : LangChain ì˜ì¡´ì„±, ê·¸ë˜í”„ êµ¬ì¡° í•™ìŠµ í•„ìš”

---

**ë‹¤ìŒ:** [ì•„í‚¤í…ì²˜ ê¹Šì´ ì´í•´í•˜ê¸°](./architecture.md)ì—ì„œ Pregel, Apache Beam, XStateì˜ ë‚´ë¶€ ë™ì‘ì„ ìƒì„¸íˆ ì•Œì•„ë´…ë‹ˆë‹¤.
